{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (91700,10) (175,9) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1fc4a229bf72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# 调用分类函数对未知数据分类\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0moutputLabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkNN_Classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_study\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your input is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"and classified to class: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/Clustering/KNN.py\u001b[0m in \u001b[0;36mkNN_Classify\u001b[0;34m(inX, dataSet, labels, k)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkNN_Classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdataSetSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdiffMat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataSetSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdataSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m#关于tile函数的用法\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#>>> b=[1,3,5]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (91700,10) (175,9) "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# coding=utf-8\n",
    "import KNN\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_study = np.loadtxt('data_study.txt')#此处要进行np的import  import numpy as np\n",
    "X_check = np.loadtxt('data_check.txt')\n",
    "#获取标签,原来的标签是最后一行，并且是2和4，要改一下\n",
    "label = X_study[:,9]\n",
    "label = label/2 -1\n",
    "for i in range(len(label)): \n",
    "    if label[i] == 0: \n",
    "        label[i] = 1\n",
    "    else:\n",
    "        label[i] = 0\n",
    "X_study = np.delete(X_study,9,axis=1)\n",
    "#数据标准化\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#映射到均匀分布\n",
    "#quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\n",
    "#x_pac = quantile_transformer.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "#PCA降到一维，实验证明，这样效果最好\n",
    "pca=PCA(n_components=1)\n",
    "pca.fit(X_study)\n",
    "x_study = pca.transform(X_study)\n",
    "\n",
    "# 生成数据集和类别标签\n",
    "#dataSet, labels = KNN.createDataSet()\n",
    "# 定义一个未知类别的数据\n",
    "#testX = array([1.2, 1.0])\n",
    "k = 3\n",
    "# 调用分类函数对未知数据分类\n",
    "outputLabel = KNN.kNN_Classify(X_check, X_study, label, 3)\n",
    "print(\"Your input is:\", testX, \"and classified to class: \", outputLabel)\n",
    " \n",
    "#testX = array([0.1, 0.3])\n",
    "#outputLabel = KNN.kNN_Classify(testX, dataSet, labels, 3)\n",
    "#print(\"Your input is:\", testX, \"and classified to class: \", outputLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]\n",
      "result_NMI: 0.8056428063666358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liyunzhe/Downloads/enter/lib/python3.7/site-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_study = np.loadtxt('data_study.txt')#此处要进行np的import  import numpy as np\n",
    "X_check = np.loadtxt('data_check.txt')\n",
    "#获取标签,原来的标签是最后一行，并且是2和4，要改一下\n",
    "labels = X_study[:,9]\n",
    "labels = labels/2 -1\n",
    "for i in range(len(labels)): \n",
    "    if labels[i] == 0: \n",
    "        labels[i] = 1\n",
    "    else:\n",
    "        labels[i] = 0\n",
    "X_study = np.delete(X_study,9,axis=1)\n",
    "label_check = X_check[:,9]\n",
    "label_check = label_check/2 -1\n",
    "for i in range(len(label_check)): \n",
    "    if label_check[i] == 0: \n",
    "        label_check[i] = 1\n",
    "    else:\n",
    "        label_check[i] = 0\n",
    "X_check = np.delete(X_check,9,axis=1)\n",
    "#print(labels)\n",
    "total = list()\n",
    "\n",
    "pca=PCA(n_components=1)\n",
    "pca.fit(X_study)\n",
    "x_study = pca.transform(X_study)\n",
    "\n",
    "pca.fit(X_check)\n",
    "x_check = pca.transform(X_check)\n",
    "\n",
    "def distance(k, X_train, Y_train, x):\n",
    "    assert 1 <= k <= X_train.shape[0], \"K must be valid\"\n",
    "    assert X_train.shape[0] == Y_train.shape[0], \"the size of X_train must equal to the size of y_train\"\n",
    "    assert X_train.shape[1] == x.shape[0], \"the feature number of x must be equal to X_train\"\n",
    "    distance = [np.sum(abs(x_train - x)) for x_train in X_train]\n",
    "    nearest = np.argsort(distance)\n",
    "    topk_y = [Y_train[i] for i in nearest[:k]]\n",
    "    votes = Counter(topk_y)\n",
    "    return votes.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #X_train = np.array([[1.0, 3.5],\n",
    "     #                  [2.0, 7],\n",
    "    #                   [3.0, 10.5],\n",
    "    #                   [4.0, 14],\n",
    "    #                   [5, 25],\n",
    "    #                   [6, 30],\n",
    "    #                   [7, 35],\n",
    "     #                  [8, 40]])\n",
    "    #Y_train = np.array([0, 0, 0, 0, 1, 1, 1, 1])\n",
    "    for xr in x_check:\n",
    "    #x = np.array([8,4,5,1,2,1,7,3,1])\n",
    "        label = distance(5, x_study, labels, xr)\n",
    "        #print(label)\n",
    "        \n",
    "        total.append(label)\n",
    "    print(total)\n",
    "    \n",
    "    result_NMI=metrics.normalized_mutual_info_score(label_check, total)\n",
    "    print(\"result_NMI:\",result_NMI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
